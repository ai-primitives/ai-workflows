import { Provider, LanguageModel } from 'ai'
import { createOpenAI } from '@ai-sdk/openai'
import { LanguageModelV1, LanguageModelV1CallOptions, LanguageModelV1Result } from '@ai-sdk/provider'
import { promises as fs } from 'fs'
import path from 'path'

async function createMDXFile(name: string, options: any = {}): Promise<void> {
  const mdx = `---
$type: https://mdx.org.ai/AIFunction
$context: https://schema.org
name: ${name}
description: AI function that handles ${name} operation
input: ${JSON.stringify(options.input || {
    type: 'object',
    properties: {}
  })}
output: ${JSON.stringify(options.output || {
    type: 'object',
    properties: {}
  })}
---

# ${name}

This function is auto-generated by the AI Workflow system.

## Input Schema
\`\`\`typescript
interface Input {
  // TODO: Define input properties
}
\`\`\`

## Output Schema
\`\`\`typescript
interface Output {
  // TODO: Define output properties
}
\`\`\`

## Example Usage
\`\`\`typescript
const result = await ai.${name}({ /* input */ })
\`\`\`
`
  await fs.mkdir(path.dirname(options.mdxPath || path.join(process.cwd(), 'functions', `${name}.mdx`)), { recursive: true })
  await fs.writeFile(options.mdxPath || path.join(process.cwd(), 'functions', `${name}.mdx`), mdx)
}

export function createAIProxy(): {
  ai: LanguageModel
  gpt: Provider
  list: string[]
} {
  const provider = createOpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    compatibility: 'strict'
  })

  const aiProxy = new Proxy({} as LanguageModel, {
    get(target: any, prop: PropertyKey) {
      if (typeof prop === 'symbol' || prop === 'then' || prop in target) {
        return target[prop]
      }

      return async function(...args: any[]): Promise<LanguageModelV1Result> {
        const mdxPath = path.join(process.cwd(), 'functions', `${String(prop)}.mdx`)

        try {
          await fs.access(mdxPath)
        } catch {
          await createMDXFile(String(prop), { mdxPath })
        }

        const options: LanguageModelV1CallOptions = {
          prompt: [{
            role: 'user',
            content: [{
              type: 'text',
              text: String(args[0])
            }]
          }],
          temperature: 0.7,
          maxTokens: 1000
        }

        // Use AI SDK for completions
        const result = await provider.languageModel('gpt-4').doGenerate(options)

        return {
          ...result,
          experimental_output: undefined,
          toolResults: [],
          steps: [],
          experimental_providerMetadata: {}
        }
      }
    },

    apply(target: any, thisArg: any, args: any[]) {
      return target.apply(thisArg, args)
    }
  })

  return {
    ai: aiProxy,
    gpt: provider,
    list: ['summarize', 'sentiment', 'reviewKPIs']
  }
}

export const { ai, gpt, list } = createAIProxy()
